# first-captioning

A project to play around and experiment with **image captioning**. Copied directly from https://www.tensorflow.org/tutorials/text/image_captioning, based on the architecture of Show, Attend & Tell https://arxiv.org/abs/1502.03044


# About dataset

The [COCO dataset](http://cocodataset.org) (2014) is a large-scale object detection, segmentation, and captioning dataset.
We will only be focused on captioning.

The training set contains 82783 images (13GB), each with at least 5 captions. The validation set contains 41K images (6GB).

 
